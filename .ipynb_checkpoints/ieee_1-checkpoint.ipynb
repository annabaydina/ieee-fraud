{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:13:05.934421Z",
     "start_time": "2019-08-07T15:13:05.916063Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "# sys.path.append('..\\Python Scripts\\pipeline')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle\n",
    "from scipy.stats import uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm\n",
    "from scipy import stats\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, validation_curve, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:13:06.062950Z",
     "start_time": "2019-08-07T15:13:05.936652Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:13:06.174474Z",
     "start_time": "2019-08-07T15:13:06.134241Z"
    },
    "code_folding": [
     0,
     14,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def num_cat(df):\n",
    "    '''\n",
    "    Функция возвращает куски исходного датафрейма. Куски состоят из категориальных фич и из числовых\n",
    "    '''\n",
    "    categorical_features = df.select_dtypes(include = [\"object\"]).columns\n",
    "    numerical_features = df.select_dtypes(exclude = [\"object\"]).columns\n",
    "    if 'target' in numerical_features:\n",
    "        numerical_features = numerical_features.drop('target')\n",
    "    print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "    print(\"Categorical features : \" + str(len(categorical_features)))\n",
    "\n",
    "    df_num = df[numerical_features]\n",
    "    df_cat = df[categorical_features]\n",
    "    return df_num, df_cat\n",
    "def missing_values_table(df):\n",
    "    '''\n",
    "    Функция возвращает таблицу с количеством и долей пропущенных значений в датафрейме\n",
    "    '''\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns\n",
    "def reduce_memory_usage(df):\n",
    "    '''\n",
    "    iterate through all the columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    '''\n",
    "    start_mem = df.memory_usage().sum()/1024**2\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if (col_type != object) & (col_type != 'datetime64[ns]'):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum()/1024**2\n",
    "    print('Memory usage: Before|{:.2f} MB || After|{:.2f} MB || Decreased|{:.1f}%'.format(start_mem, end_mem, 100*(1 - end_mem/start_mem)))\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:13:06.318301Z",
     "start_time": "2019-08-07T15:13:06.314593Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.listdir('../ieee/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:13:06.324742Z",
     "start_time": "2019-08-07T15:13:06.321942Z"
    }
   },
   "outputs": [],
   "source": [
    "# folder_path = '../input/'\n",
    "# subm = reduce_memory_usage(pd.read_csv(f'../input/ieee-fraud-detection/sample_submission.csv'))\n",
    "\n",
    "# te_id = reduce_memory_usage(pd.read_csv(f'../input/ieee-fraud-detection/test_identity.csv'))\n",
    "# te_tr = reduce_memory_usage(pd.read_csv(f'../input/ieee-fraud-detection/test_transaction.csv'))\n",
    "# tr_id = reduce_memory_usage(pd.read_csv(f'../input/ieee-fraud-detection/train_identity.csv'))\n",
    "# tr_tr = reduce_memory_usage(pd.read_csv(f'../input/ieee-fraud-detection/train_transaction.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:13:06.330959Z",
     "start_time": "2019-08-07T15:13:06.328132Z"
    }
   },
   "outputs": [],
   "source": [
    "# subm = reduce_memory_usage(pd.read_csv(f'../ieee/input/sample_submission.csv'))\n",
    "# te_id = reduce_memory_usage(pd.read_csv(f'../ieee/input/test_identity.csv'))\n",
    "# te_tr = reduce_memory_usage(pd.read_csv(f'../ieee/input/test_transaction.csv'))\n",
    "# tr_id = reduce_memory_usage(pd.read_csv(f'../ieee/input/train_identity.csv'))\n",
    "# tr_tr = reduce_memory_usage(pd.read_csv(f'../ieee/input/train_transaction.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:13:06.335312Z",
     "start_time": "2019-08-07T15:13:06.332847Z"
    }
   },
   "outputs": [],
   "source": [
    "files = ['../ieee/input/test_identity.csv', \n",
    "         '../ieee/input/test_transaction.csv',\n",
    "         '../ieee/input/train_identity.csv',\n",
    "         '../ieee/input/train_transaction.csv',\n",
    "         '../ieee/input/sample_submission.csv']\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:14:18.611707Z",
     "start_time": "2019-08-07T15:13:06.336812Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    test_id, test_tr, train_id, train_tr, sub = pool.map(load_data, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:14:45.046914Z",
     "start_time": "2019-08-07T15:14:18.616884Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train_tr, train_id, on='TransactionID', how='left')\n",
    "test = pd.merge(test_tr, test_id, on='TransactionID', how='left')\n",
    "\n",
    "del test_id, test_tr, train_id, train_tr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:14:53.775264Z",
     "start_time": "2019-08-07T15:14:45.049060Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_num, tr_cat = num_cat(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:15:01.920225Z",
     "start_time": "2019-08-07T15:14:53.779099Z"
    }
   },
   "outputs": [],
   "source": [
    "te_num, te_cat = num_cat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:15:03.754316Z",
     "start_time": "2019-08-07T15:15:01.921929Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "START_DATE = '2017-12-01' \n",
    "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\") \n",
    "\n",
    "for dataset in (train, test): \n",
    "    dataset[\"Date\"] = dataset['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x))) \n",
    "    dataset['Weekdays'] = dataset['Date'].dt.dayofweek \n",
    "    dataset['Hours'] = dataset['Date'].dt.hour \n",
    "    dataset['Days'] = dataset['Date'].dt.day \n",
    "    dataset['isNight'] = dataset['Hours'].map(lambda x: 1 if (x >= 23 or x < 5) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:13.164704Z",
     "start_time": "2019-08-07T15:15:03.756079Z"
    }
   },
   "outputs": [],
   "source": [
    "train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "train['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "train['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "test['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "test['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "train['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "train['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:24.220358Z",
     "start_time": "2019-08-07T15:16:13.167609Z"
    }
   },
   "outputs": [],
   "source": [
    "train['nulls1'] = train.isna().sum(axis=1)\n",
    "test['nulls1'] = test.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:26.249680Z",
     "start_time": "2019-08-07T15:16:24.222862Z"
    }
   },
   "outputs": [],
   "source": [
    "emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n",
    "us_emails = ['gmail', 'net', 'edu']\n",
    "\n",
    "for c in ['P_emaildomain', 'R_emaildomain']:\n",
    "    train[c + '_bin'] = train[c].map(emails)\n",
    "    test[c + '_bin'] = test[c].map(emails)\n",
    "    \n",
    "    train[c + '_suffix'] = train[c].map(lambda x: str(x).split('.')[-1])\n",
    "    test[c + '_suffix'] = test[c].map(lambda x: str(x).split('.')[-1])\n",
    "    \n",
    "    train[c + '_suffix'] = train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "    test[c + '_suffix'] = test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:58.563750Z",
     "start_time": "2019-08-07T15:16:26.251223Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "for f in train.columns:\n",
    "    if  train[f].dtype=='object': \n",
    "        train[f] = train[f].replace(\"nan\", \"other\")\n",
    "        train[f] = train[f].replace(np.nan, \"other\")\n",
    "        test[f] = test[f].replace(\"nan\", \"other\")\n",
    "        test[f] = test[f].replace(np.nan, \"other\")\n",
    "        \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:58.597985Z",
     "start_time": "2019-08-07T15:16:58.566181Z"
    }
   },
   "outputs": [],
   "source": [
    "# New feature - decimal part of the transaction amount\n",
    "train['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:58.658983Z",
     "start_time": "2019-08-07T15:16:58.599916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count encoding for card1 feature. \n",
    "# Explained in this kernel: https://www.kaggle.com/nroman/eda-for-cis-fraud-detection\n",
    "train['card1_count_full'] = train['card1'].map(pd.concat([train['card1'], test['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "test['card1_count_full'] = test['card1'].map(pd.concat([train['card1'], test['card1']], ignore_index=True).value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:58.666765Z",
     "start_time": "2019-08-07T15:16:58.664370Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Some arbitrary features interaction\n",
    "# for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n",
    "#                 'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n",
    "\n",
    "#     f1, f2 = feature.split('__')\n",
    "#     train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n",
    "#     test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n",
    "\n",
    "#     le = LabelEncoder()\n",
    "#     le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n",
    "#     train[feature] = le.transform(list(train[feature].astype(str).values))\n",
    "#     test[feature] = le.transform(list(test[feature].astype(str).values))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:58.752123Z",
     "start_time": "2019-08-07T15:16:58.671196Z"
    }
   },
   "outputs": [],
   "source": [
    "for feature in ['id_34', 'id_36']:\n",
    "    # Count encoded for both train and test\n",
    "    train[feature + '_count_full'] = train[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    test[feature + '_count_full'] = test[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:16:58.889761Z",
     "start_time": "2019-08-07T15:16:58.754241Z"
    }
   },
   "outputs": [],
   "source": [
    "for feature in ['id_01', 'id_31', 'id_33', 'id_35', 'id_36']:\n",
    "    # Count encoded separately for train and test\n",
    "    train[feature + '_count_dist'] = train[feature].map(train[feature].value_counts(dropna=False))\n",
    "    test[feature + '_count_dist'] = test[feature].map(test[feature].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:20:19.901325Z",
     "start_time": "2019-08-07T15:20:07.727928Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']\n",
    "test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T14:38:14.756052Z",
     "start_time": "2019-08-07T14:37:51.711153Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# for f in tr_cat.columns:\n",
    "#     if  tr_cat[f].dtype=='object': \n",
    "        \n",
    "#         tr_cat[f] = tr_cat[f].replace(\"nan\", \"other\")\n",
    "#         tr_cat[f] = tr_cat[f].replace(np.nan, \"other\")\n",
    "\n",
    "#         lbl = preprocessing.LabelEncoder()\n",
    "#         lbl.fit(list(tr_cat[f].values) )\n",
    "        \n",
    "#         tr_cat[f] = lbl.transform(list(tr_cat[f].values))\n",
    "        \n",
    "# for f in te_cat.columns:\n",
    "#     if  te_cat[f].dtype=='object': \n",
    "        \n",
    "#         te_cat[f] = te_cat[f].replace(\"nan\", \"other\")\n",
    "#         te_cat[f] = te_cat[f].replace(np.nan, \"other\")\n",
    "        \n",
    "#         lbl = preprocessing.LabelEncoder()\n",
    "#         lbl.fit(list(te_cat[f].values) )\n",
    "\n",
    "#         te_cat[f] = lbl.transform(list(te_cat[f].values))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:37:20.688324Z",
     "start_time": "2019-08-07T15:22:23.485Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoost, Pool, cv\n",
    "\n",
    "# cv_data = tr_cat\n",
    "# labels = y\n",
    "# cat_features = np.arange(tr_cat.shape[1])\n",
    "\n",
    "# cv_dataset = Pool(data=cv_data,\n",
    "#                   label=labels,\n",
    "#                   cat_features=cat_features)\n",
    "\n",
    "# params = {\"iterations\": 100,\n",
    "#           \"depth\": 2,\n",
    "#           \"loss_function\": \"Logloss\",\n",
    "#           'custom_metric': \"AUC\",\n",
    "#           \"verbose\": False}\n",
    "\n",
    "# model = CatBoost(params)\n",
    "# #train the model\n",
    "# model.fit(cv_data, labels) \n",
    "\n",
    "# # # make the prediction using the resulting model\n",
    "# # preds_class = model.predict(te_cat)\n",
    "# preds_proba = model.predict_proba(te_cat)\n",
    "\n",
    "# # scores = cv(cv_dataset,\n",
    "# #             params,\n",
    "# #             fold_count=2, \n",
    "# #             plot=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:37:37.830152Z",
     "start_time": "2019-08-07T15:37:37.819952Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47,\n",
    "          'n_jobs':30\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:20:27.354272Z",
     "start_time": "2019-08-07T15:20:27.351668Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:21:39.501051Z",
     "start_time": "2019-08-07T15:21:37.455752Z"
    }
   },
   "outputs": [],
   "source": [
    "X.drop('Date', axis=1, inplace=True)\n",
    "test.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:46:35.842685Z",
     "start_time": "2019-08-07T15:37:42.025883Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = np.zeros(len(test))\n",
    "oof = np.zeros(len(X))\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = X.columns\n",
    "\n",
    "training_start_time = time()\n",
    "\n",
    "\n",
    "for fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n",
    "    \n",
    "    start_time = time()\n",
    "    print('Training on fold {}'.format(fold + 1))\n",
    "    \n",
    "    trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X.iloc[test_idx], label=y.iloc[test_idx])\n",
    "    \n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    8000,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds=500)\n",
    "    \n",
    "    preds += clf.predict(test)\n",
    "    oof[test_idx] = clf.predict(X.iloc[test_idx])\n",
    "    feature_importances['fold_{}'.format(fold + 1)] = clf.feature_importance()\n",
    "    \n",
    "    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n",
    "    \n",
    "print('-' * 30)\n",
    "print('Training has finished.')\n",
    "print('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n",
    "print('OOF AUC:', roc_auc_score(y, oof))\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances['average'] = feature_importances[['fold_{}'.format(fold + 1) for fold in range(folds.n_splits)]].mean(axis=1)\n",
    "feature_importances.to_csv('feature_importances.csv')\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "sns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\n",
    "plt.title('50 TOP feature importance over {} folds average'.format(folds.n_splits));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['isFraud'] = preds / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subm['isFraud'] = result_dict_lgb['prediction']\n",
    "# sub.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "all_blends =  pd.read_csv(f'../ieee/input/sample_submission.csv', index_col=0)\n",
    "\n",
    "sub = all_blends.copy()\n",
    "sub['isFraud'] =all_blends['isFraud'].values*0.6 + subm['isFraud'].values*0.4\n",
    "\n",
    "sub.to_csv('try5.csv', float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:37:20.696318Z",
     "start_time": "2019-08-07T15:22:36.781Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# l_num2mean = []\n",
    "# for col in tr_num.columns:\n",
    "#     if len(tr_num[col].value_counts()) > 1000:\n",
    "#         print('-------------%s-------------' %col)\n",
    "#         l_num2mean.append(col)\n",
    "# #         print(tr_num[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:37:20.692387Z",
     "start_time": "2019-08-07T15:22:35.285Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for col in l_num2mean:\n",
    "#     print(col, ' ', train[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T07:51:17.738990Z",
     "start_time": "2019-08-06T07:51:17.735000Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for item in ['TransactionID',\n",
    "#  'TransactionDT', 'Date']:\n",
    "#     l_num2mean.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:37:20.700397Z",
     "start_time": "2019-08-07T15:22:44.783Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def nan2mean(df, col):\n",
    "\n",
    "#     df[col] = df[col].fillna(df[col].mean())\n",
    "#        #print(\"Mean-\"+str(df[x].mean()))\n",
    "#     return df\n",
    "\n",
    "# q=0\n",
    "# l = len(l_num2mean)\n",
    "\n",
    "# for col in l_num2mean:\n",
    "#     print(col)\n",
    "#     q+=1\n",
    "#     print('%d/%d' %(q,l))\n",
    "#     train[col]=nan2mean(train, col)\n",
    "\n",
    "# for col in l_num2mean:\n",
    "#     test[col]=nan2mean(test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# START_DATE = '2017-12-01' \n",
    "# startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\") \n",
    "\n",
    "# for dataset in (train,test): \n",
    "#     dataset[\"Date\"] = dataset['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x))) \n",
    "#     dataset['_Weekdays'] = dataset['Date'].dt.dayofweek \n",
    "#     dataset['_Hours'] = dataset['Date'].dt.hour \n",
    "#     dataset['_Days'] = dataset['Date'].dt.day \n",
    "\n",
    "# train = train.drop(['TransactionDT'],axis=1) \n",
    "# test = test.drop(['TransactionDT'],axis=1)\n",
    "\n",
    "# for item in tr_cat.columns:\n",
    "#     if len(tr_cat[item].value_counts()) > 6:\n",
    "#         print(item, len(tr_cat[item].value_counts()))\n",
    "\n",
    "# le_cols = ['id_31','P_emaildomain','R_emaildomain', 'id_30', 'id_33','DeviceInfo']\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# for col in le_cols:\n",
    "#     if col in train.columns:\n",
    "#         le = preprocessing.LabelEncoder()\n",
    "#         le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "#         train[col] = le.transform(list(train[col].astype(str).values))\n",
    "#         test[col] = le.transform(list(test[col].astype(str).values))   \n",
    "\n",
    "# def yesno(df, col):\n",
    "#     df[col] = df[col].map({'T':1, 'F':0})\n",
    "#     return df\n",
    "\n",
    "# def fnf(df, col):\n",
    "#     df[col] = df[col].map({'Found':1, 'NotFound':0})\n",
    "#     return df\n",
    "\n",
    "# for col in ['id_37', 'id_36', 'id_35', 'id_34', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']:\n",
    "#     train = yesno(train, col)\n",
    "#     test = yesno(test, col)\n",
    "\n",
    "# for col in ['id_27', 'id_29', 'id_16', 'id_12']:\n",
    "#     train = fnf(train, col)\n",
    "#     test = fnf(test, col)\n",
    "\n",
    "# num, cat = num_cat(train)\n",
    "\n",
    "# def onehot_encoder( df, column_name):\n",
    "#     dummies = pd.get_dummies(df[column_name], prefix=\"\"+ column_name)\n",
    "#     df = df.join(dummies)\n",
    "#     df = df.drop([column_name], axis=1)\n",
    "#     return df\n",
    "\n",
    "# for col in cat.columns:\n",
    "#     train = onehot_encoder(train, col)\n",
    "#     test = onehot_encoder(test, col)\n",
    "\n",
    "# num, cat = num_cat(train)\n",
    "\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:13:37.445524Z",
     "start_time": "2019-08-05T15:07:49.262429Z"
    }
   },
   "outputs": [],
   "source": [
    "# threshold = 0.985\n",
    "    \n",
    "# # Absolute value correlation matrix\n",
    "# corr_matrix = train[train['isFraud'].notnull()].corr().abs()\n",
    "\n",
    "# # Getting the upper triangle of correlations\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Select columns with correlations above threshold\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('There are %d columns to remove.' % (len(to_drop)))\n",
    "# train = train.drop(columns = to_drop)\n",
    "# test = test.drop(columns = to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T15:37:20.704189Z",
     "start_time": "2019-08-07T15:23:07.815Z"
    }
   },
   "outputs": [],
   "source": [
    "# X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
    "# y = train.sort_values('TransactionDT')['isFraud']\n",
    "# X_test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)\n",
    "# # del train\n",
    "# # test = test[[\"TransactionDT\", 'TransactionID']]\n",
    "\n",
    "# n_fold = 5\n",
    "# # folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# # folds = KFold(n_splits=5)\n",
    "# folds = StratifiedKFold(n_splits=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:23:58.960442Z",
     "start_time": "2019-08-05T15:23:58.952368Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# import time\n",
    "# import lightgbm as lgb\n",
    "# def eval_auc(y_true, y_pred):\n",
    "#     \"\"\"\n",
    "#     Fast auc eval function for lgb.\n",
    "#     \"\"\"\n",
    "#     return 'auc', fast_auc(y_true, y_pred), True\n",
    "# metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n",
    "#                         'catboost_metric_name': 'AUC',\n",
    "#                         'sklearn_scoring_function': metrics.roc_auc_score},\n",
    "#                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:23:19.290494Z",
     "start_time": "2019-08-05T15:23:19.281574Z"
    }
   },
   "outputs": [],
   "source": [
    "# def fast_auc(y_true, y_prob):\n",
    "#     \"\"\"\n",
    "#     fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
    "#     \"\"\"\n",
    "#     y_true = np.asarray(y_true)\n",
    "#     y_true = y_true[np.argsort(y_prob)]\n",
    "#     nfalse = 0\n",
    "#     auc = 0\n",
    "#     n = len(y_true)\n",
    "#     for i in range(n):\n",
    "#         y_i = y_true[i]\n",
    "#         nfalse += (1 - y_i)\n",
    "#         auc += y_i * nfalse\n",
    "#     auc /= (nfalse * (n - nfalse))\n",
    "#     return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:18:21.053327Z",
     "start_time": "2019-08-05T15:18:21.031816Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', \n",
    "                               columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=10000, \n",
    "                               splits=None, n_folds=3, averaging='usual', n_jobs=30):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    A function to train a variety of classification models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n",
    "                        'catboost_metric_name': 'AUC',\n",
    "                        'sklearn_scoring_function': metrics.roc_auc_score},\n",
    "                    }\n",
    "    \n",
    "    result_dict = {}\n",
    "    if averaging == 'usual':\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros((len(X), 1))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros((len(X_test), 1))\n",
    "        \n",
    "    elif averaging == 'rank':\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros((len(X), 1))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros((len(X_test), 1))\n",
    "\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = n_jobs)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        if averaging == 'usual':\n",
    "            \n",
    "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "            \n",
    "            prediction += y_pred.reshape(-1, 1)\n",
    "\n",
    "        elif averaging == 'rank':\n",
    "                                  \n",
    "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "                                  \n",
    "            prediction += pd.Series(y_pred).rank().values.reshape(-1, 1)        \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "            result_dict['top_columns'] = cols\n",
    "        \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:54:09.606273Z",
     "start_time": "2019-08-05T15:24:03.280194Z"
    }
   },
   "outputs": [],
   "source": [
    "# params = {'num_leaves': 256,\n",
    "#           'min_child_samples': 79,\n",
    "#           'objective': 'binary',\n",
    "#           'max_depth': 13,\n",
    "#           'learning_rate': 0.03,\n",
    "#           \"boosting_type\": \"gbdt\",\n",
    "#           \"subsample_freq\": 3,\n",
    "#           \"subsample\": 0.9,\n",
    "#           \"bagging_seed\": 11,\n",
    "#           \"metric\": 'auc',\n",
    "#           \"verbosity\": -1,\n",
    "#           'reg_alpha': 0.3,\n",
    "#           'reg_lambda': 0.3,\n",
    "#           'colsample_bytree': 0.9,\n",
    "#           #'categorical_feature': cat_cols\n",
    "#          }\n",
    "# result_dict_lgb = train_model_classification(X=X_train, X_test=X_test, y=y_train, params=params, folds=folds, model_type='lgb', eval_metric='auc', plot_feature_importance=True,\n",
    "#                                                       verbose=500, early_stopping_rounds=200, n_estimators=10000, averaging='usual', n_jobs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:55:51.379772Z",
     "start_time": "2019-08-05T15:55:51.370561Z"
    }
   },
   "outputs": [],
   "source": [
    "subm['isFraud'] = result_dict_lgb['prediction']\n",
    "# sub.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "all_blends =  pd.read_csv(f'../ieee/input/sample_submission.csv', index_col=0)\n",
    "\n",
    "sub = all_blends.copy()\n",
    "sub['isFraud'] =all_blends['isFraud'].values*0.6 + subm['isFraud'].values*0.4\n",
    "\n",
    "sub.to_csv('try4.csv', float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv('X_train.csv')\n",
    "# X_test.to_csv('X_test.csv')\n",
    "# y_train.to_csv('y_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'n_estimators': 1000,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'num_leaves': 20,\n",
    "#     'max_depth': 1,\n",
    "#     'min_child_weight': 10,\n",
    "#     'lambda_l1':2,\n",
    "#     'lambda_l2':3,\n",
    "#     'min_data_in_leaf' :10,\n",
    "#     'min_sum_hessian_in_leaf' : 0.0001,\n",
    "#     'bagging_fraction' : 0.8,\n",
    "#     'max_bin': 12,\n",
    "#     'feature_fraction' : 0.9,\n",
    "#     'bagging_freq' : 100,\n",
    "#     'min_gain_to_split': 0.1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# from hyperopt import hp, tpe\n",
    "# from hyperopt.fmin import fmin\n",
    "\n",
    "# def objective(params):\n",
    "\n",
    "#     print(\"############## New Run ################\")\n",
    "#     print(\"PARAMETERS: \")\n",
    "#     print(f\"params  = {params}\")\n",
    "    \n",
    "#     params = {\n",
    "#     'n_estimators': int(params['n_estimators']),\n",
    "#     'learning_rate': params['learning_rate'],\n",
    "#     'num_leaves': int(params['num_leaves']),\n",
    "#     'max_depth': 1,\n",
    "#     'min_child_weight': int(params['min_child_weight']),\n",
    "#     'lambda_l1':params['lambda_l1'],\n",
    "#     'lambda_l2':params['lambda_l2'],\n",
    "#     'min_data_in_leaf' :int(params['min_data_in_leaf']),\n",
    "#     'min_sum_hessian_in_leaf' : params['min_sum_hessian_in_leaf'],\n",
    "#     'bagging_fraction' : params['bagging_fraction'],\n",
    "#     'max_bin': int(params['max_bin']),\n",
    "#     'feature_fraction' : params['feature_fraction'],\n",
    "#     'bagging_freq' : int(params['bagging_freq']),\n",
    "#     'min_gain_to_split': params['min_gain_to_split']\n",
    "#     }\n",
    "    \n",
    "#     EPOCHS = 3\n",
    "#     tss = TimeSeriesSplit(n_splits=EPOCHS)\n",
    "#     score_mean = 0\n",
    "#     print(\"CV SCORE: \")\n",
    "#     for tr_idx, val_idx in tss.split(X_train, y_train):\n",
    "#         clf = lightgbm.LGBMClassifier(n_estimators=params['n_estimators'],\n",
    "#                 learning_rate=params['learning_rate'],\n",
    "#                 num_leaves=params['num_leaves'],\n",
    "#                 max_depth=params['max_depth'],\n",
    "#                 min_child_weight=params['min_child_weight'],\n",
    "#                 lambda_l1=params['lambda_l1'],\n",
    "#                 lambda_l2=params['lambda_l2'],\n",
    "#                 min_data_in_leaf=params['min_data_in_leaf'],\n",
    "#                 min_sum_hessian_in_leaf=params['min_sum_hessian_in_leaf'],\n",
    "#                 bagging_fraction=params['bagging_fraction'],\n",
    "#                 max_bin=params['max_bin'],\n",
    "#                 feature_fraction=params['feature_fraction'],\n",
    "#                 bagging_freq=params['bagging_freq'],\n",
    "#                 min_gain_to_split=params['min_gain_to_split'])\n",
    "\n",
    "#         X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n",
    "#         y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "#         clf.fit(X_tr, y_tr)\n",
    "        \n",
    "#         y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "#         score = roc_auc_score(y_vl, y_pred_train)\n",
    "#         score_mean += score\n",
    "#         print(f'ROC AUC {score}')\n",
    "        \n",
    "#     del X_tr, X_vl, y_tr, y_vl, clf, y_pred_train    \n",
    "#     gc.collect()\n",
    "#     print(f'Mean ROC_AUC: {score_mean / EPOCHS} \\n')\n",
    "#     return -(score_mean / EPOCHS)\n",
    "\n",
    "\n",
    "# space = {\n",
    "#     'n_estimators': hp.quniform('n_estimators', 900, 910, 1),\n",
    "#     'num_leaves': hp.quniform('num_leaves', 5, 600, 1),\n",
    "#     'min_child_weight': hp.quniform('min_child_weight', 1, 700, 1),\n",
    "#     'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "#     'max_bin': hp.quniform('max_bin', 5, 500, 1),\n",
    "#     'min_data_in_leaf': hp.quniform('min_data_in_leaf', 10, 500, 1), \n",
    "#     'lambda_l1': hp.uniform('lambda_l1', 0, 3), \n",
    "#     'lambda_l2': hp.uniform('lambda_l2', 0, 3),\n",
    "# #     'min_data_in_leaf' :hp.quniform('min_data_in_leaf', 5, 50, 1),\n",
    "#     'min_sum_hessian_in_leaf' : hp.uniform('min_sum_hessian_in_leaf', 0, 0.01),\n",
    "#     'bagging_fraction' : hp.uniform('bagging_fraction', 0, 0.9),\n",
    "#     'max_bin': hp.quniform('max_bin', 10, 500, 1),\n",
    "#     'feature_fraction' : hp.uniform('feature_fraction', 0, 0.9),\n",
    "#     'bagging_freq' : hp.quniform('bagging_freq', 10, 1000, 10),\n",
    "#     'min_gain_to_split': hp.uniform('min_gain_to_split', 0.1, 1),     \n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set algoritm parameters\n",
    "# best = fmin(fn=objective,\n",
    "#             space=space,\n",
    "#             algo=tpe.suggest,\n",
    "#             max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best['num_leaves'] = int(best['num_leaves'])\n",
    "# best['bagging_freq'] = int(best['bagging_freq'])\n",
    "# best['max_bin'] = int(best['max_bin'])\n",
    "# best['min_child_weight'] = int(best['min_child_weight'])\n",
    "# best['min_data_in_leaf'] = int(best['min_data_in_leaf'])\n",
    "# best['n_estimators'] = int(best['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = {\n",
    "#     'n_estimators': 5000,\n",
    "#     'bagging_fraction': 0.1,\n",
    "#  'colsample_bytree': 0.6,\n",
    "#  'feature_fraction': 0.788941629218398,\n",
    "#  'max_depth': 30,\n",
    "#  'min_child_samples': 100,\n",
    "#  'min_child_weight': 1.004827043917695e-05,\n",
    "#  'min_data_in_leaf': 20,\n",
    "#  'num_leaves': 250,\n",
    "#  'reg_alpha': 1.6158062156738595,\n",
    "#  'reg_lambda': 1.0000000104049402,\n",
    "#  'subsample': 0.7999999740778657}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb = lightgbm.LGBMClassifier(**best)\n",
    "# lgb.fit(X_train, y_train, eval_metric='auc') \n",
    "\n",
    "# y_preds = lgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission_anya = pd.read_csv(f'../input/ieee-fraud-detection/sample_submission.csv', index_col='TransactionID')\n",
    "# sample_submission_anya['isFraud'] = y_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_blends =  pd.read_csv(f'../input/ensemble-on-fire/submission.csv', index_col=0)\n",
    "\n",
    "# # sub_path = \"../input/Ensemble on fire/ensemble\"\n",
    "# # all_files = os.listdir(sub_path)\n",
    "\n",
    "# # all_blends = pd.read_csv(os.path.join(sub_path, 'submission.csv'), index_col=0)\n",
    "\n",
    "# sub = all_blends.copy()\n",
    "# # sub.head()\n",
    "\n",
    "# sub['isFraud'] =all_blends['isFraud'].values*0.6 + sample_submission_anya['isFraud'].values*0.4\n",
    "\n",
    "# sub.to_csv('try3.csv', float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission['isFraud'] = y_preds\n",
    "# sample_submission.to_csv('try1.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "183px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
